{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mollnn\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From C:\\Users\\mollnn\\AppData\\Local\\Temp/ipykernel_14112/3523093596.py:43: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import argparse\n",
    "import glob\n",
    "import librosa\n",
    "from tensorflow.keras.layers import BatchNormalization, Multiply, Add\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow. keras.utils import multi_gpu_model\n",
    "import tensorflow.keras.callbacks\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import add, concatenate\n",
    "from tensorflow.keras.layers import Reshape, Lambda\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow.keras.backend as K\n",
    "import datetime\n",
    "import re\n",
    "import itertools\n",
    "import platform\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "tensorflow.compat.v1.keras.backend.set_session(sess)\n",
    "tensorflow.compat.v1.keras.backend.clear_session()  # 清理session\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset/data_thchs30\\\\data\\\\A11_0.wav.trn'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 　选择使用的GPU\n",
    "path_base = './dataset/data_thchs30'\n",
    "path_data = join(path_base, 'data')\n",
    "text_files = glob.glob(join(path_data, '*.wav.trn'))\n",
    "text_files.sort()\n",
    "text_files = text_files[:3]\n",
    "text_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 96.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['绿是阳春烟景大块文章的底色四月的林峦更是绿得鲜活秀媚诗意盎然',\n",
       " '他仅凭腰部的力量在泳道上下翻腾蛹动蛇行状如海豚一直以一头的优势领先',\n",
       " '炮眼打好了炸药怎么装岳正才咬了咬牙倏地脱去衣服光膀子冲进了水窜洞']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "for text_file in tqdm(text_files):\n",
    "    with codecs.open(text_file, encoding='utf-8') as f_read:\n",
    "        line = f_read.readline()\n",
    "        lines.append(line.strip().replace(\" \", \"\"))\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 1, 15, 16, 17, 18, 1, 19, 20, 21, 4, 3, 22, 23, 24, 25, 26, 27, 28, 29, 30], [31, 32, 33, 34, 35, 1, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 5, 53, 54, 5, 55, 1, 56, 57, 58, 59], [60, 61, 62, 63, 2, 64, 65, 66, 67, 68, 69, 70, 71, 6, 2, 6, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 2, 84, 85, 86]]\n"
     ]
    }
   ],
   "source": [
    "text_lines = lines \n",
    "tok_path = join(path_base, 'tokenizer.pickle')\n",
    "tok = Tokenizer(char_level=True)\n",
    "tok.fit_on_texts(text_lines)\n",
    "\n",
    "seq_lines = tok.texts_to_sequences(text_lines[:])\n",
    "print(seq_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    30\n",
       "1    33\n",
       "2    32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_lines = pd.Series(map(lambda x: len(x), seq_lines))\n",
    "len_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  7,  8,  9, 10, 11, 12, 13, 14,  1, 15, 16, 17, 18,  1,\n",
       "        19, 20, 21,  4,  3, 22, 23, 24, 25, 26, 27, 28, 29, 30,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [31, 32, 33, 34, 35,  1, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
       "        46, 47, 48, 49, 50, 51, 52,  5, 53, 54,  5, 55,  1, 56, 57, 58,\n",
       "        59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [60, 61, 62, 63,  2, 64, 65, 66, 67, 68, 69, 70, 71,  6,  2,  6,\n",
       "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83,  2, 84, 85, 86,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen=48\n",
    "lines = seq_lines[:]\n",
    "pad_lines = pad_sequences(lines, maxlen=maxlen, padding=\"post\", truncating=\"pre\")\n",
    "pad_lines"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8146345a349ee509da9d4fd182b457ccbe591f61b447c7a0f2cf1b2fba90cca7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensorflow_gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
