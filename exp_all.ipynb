{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mollnn\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From C:\\Users\\mollnn\\AppData\\Local\\Temp/ipykernel_16520/2307455839.py:43: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import argparse\n",
    "import glob\n",
    "import librosa\n",
    "from tensorflow.keras.layers import BatchNormalization, Multiply, Add\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow. keras.utils import multi_gpu_model\n",
    "import tensorflow.keras.callbacks\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import add, concatenate\n",
    "from tensorflow.keras.layers import Reshape, Lambda\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow.keras.backend as K\n",
    "import datetime\n",
    "import re\n",
    "import itertools\n",
    "import platform\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "tensorflow.compat.v1.keras.backend.set_session(sess)\n",
    "tensorflow.compat.v1.keras.backend.clear_session()  # 清理session\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "\n",
    "def get_mfcc(wav_file, max_mfcc_len):\n",
    "\n",
    "    y, sr = librosa.load(wav_file, mono=True)  # sr=22050,\n",
    "    mfcc = librosa.feature.mfcc(y, sr)\n",
    "    if max_mfcc_len > mfcc.shape[1]:\n",
    "        mfcc_feature = np.pad(\n",
    "            mfcc, ((0, 0), (0, max_mfcc_len-mfcc.shape[1])), 'constant')\n",
    "    else:\n",
    "        mfcc_feature = mfcc[:, :max_mfcc_len]\n",
    "    return mfcc_feature\n",
    "\n",
    "\n",
    "def create_mfcc_mat(wav_files, path='', save_name='mfcc_vec_all', max_mfcc_len=640):\n",
    "\n",
    "    mfcc_mat = []\n",
    "    for wav_file in tqdm(wav_files):\n",
    "        mfcc_vec = get_mfcc(wav_file, max_mfcc_len)\n",
    "        mfcc_mat.append(mfcc_vec)\n",
    "    mfcc_mat = np.array(mfcc_mat).transpose(0, 2, 1)\n",
    "    np.save(join(path, save_name), mfcc_mat)\n",
    "\n",
    "\n",
    "def get_mfcc_mat(path='', save_name='mfcc_vec_all'):\n",
    "\n",
    "    mfcc_mat = np.load(join(path, save_name+'.npy'))\n",
    "\n",
    "    return mfcc_mat\n",
    "\n",
    "\n",
    "def get_text(text_files):\n",
    "    lines = []\n",
    "    for text_file in tqdm(text_files):\n",
    "        with codecs.open(text_file, encoding='utf-8') as f_read:\n",
    "            line = f_read.readline()\n",
    "            lines.append(line.strip().replace(\" \", \"\"))\n",
    "    return lines\n",
    "\n",
    "\n",
    "def get_pad_seq(textlines, maxlen=48):\n",
    "\n",
    "    # saving\n",
    "    tok_path = join(path_base, 'tokenizer.pickle')\n",
    "    if not os.path.exists(tok_path):\n",
    "        tok = Tokenizer(char_level=True)\n",
    "        tok.fit_on_texts(text_lines)\n",
    "        with open(tok_path, 'wb') as handle:\n",
    "            pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            print('create tok')\n",
    "    # loading\n",
    "    else:\n",
    "        with open(tok_path, 'rb') as handle:\n",
    "            tok = pickle.load(handle)\n",
    "            print('load tok')\n",
    "\n",
    "    seq_lines = tok.texts_to_sequences(text_lines[:])\n",
    "    print('num of words,', len(tok.word_index.keys()))\n",
    "\n",
    "    len_lines = pd.Series(map(lambda x: len(x), seq_lines))\n",
    "    print('max_len', len_lines.max())\n",
    "\n",
    "    def new_pad_seq(line, maxlen):\n",
    "        return pad_sequences(line, maxlen=maxlen, padding='post', truncating='pre')\n",
    "\n",
    "    lines = seq_lines[:]\n",
    "    pad_lines = new_pad_seq(lines, maxlen)\n",
    "    return pad_lines, tok\n",
    "\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def get_model2(img_w=32, img_h=20, output_size=None, max_pred_len=4):\n",
    "\n",
    "    input_tensor = Input(shape=(img_w, img_h), name='the_input')\n",
    "    x = Conv1D(kernel_size=1, filters=192, padding=\"same\")(input_tensor)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Activation(\"tanh\")(x)\n",
    "\n",
    "    def res_block(x, size, rate, dim=192):\n",
    "        x_tanh = Conv1D(kernel_size=size, filters=dim,\n",
    "                        dilation_rate=rate, padding=\"same\")(x)\n",
    "        x_tanh = BatchNormalization(axis=-1)(x_tanh)\n",
    "        x_tanh = Activation(\"tanh\")(x_tanh)\n",
    "        x_sigmoid = Conv1D(kernel_size=size, filters=dim,\n",
    "                           dilation_rate=rate, padding=\"same\")(x)\n",
    "        x_sigmoid = BatchNormalization(axis=-1)(x_sigmoid)\n",
    "        x_sigmoid = Activation(\"sigmoid\")(x_sigmoid)\n",
    "        out = Multiply()([x_tanh, x_sigmoid])\n",
    "        out = Conv1D(kernel_size=1, filters=dim, padding=\"same\")(out)\n",
    "        out = BatchNormalization(axis=-1)(out)\n",
    "        out = Activation(\"tanh\")(out)\n",
    "        x = Add()([x, out])\n",
    "        return x, out\n",
    "\n",
    "    skip = []\n",
    "    for i in np.arange(0, 5):\n",
    "        for r in [1, 2, 4, 8, 16]:\n",
    "            x, s = res_block(x, size=7, rate=r)\n",
    "            skip.append(s)\n",
    "\n",
    "    skip_tensor = Add()([s for s in skip])\n",
    "    logit = Conv1D(kernel_size=1, filters=192, padding=\"same\")(skip_tensor)\n",
    "    logit = BatchNormalization(axis=-1)(logit)\n",
    "    logit = Activation(\"tanh\")(logit)\n",
    "    y_pred = Conv1D(kernel_size=1, filters=output_size,\n",
    "                    padding=\"same\", activation=\"softmax\")(logit)\n",
    "\n",
    "    # Model(inputs=input_tensor, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[max_pred_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')(\n",
    "        [y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "    # opt = Adam(lr=0.001)\n",
    "    model = Model(inputs=[input_tensor, labels,\n",
    "                  input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    # model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=opt)\n",
    "    test_func = K.function(\n",
    "        [input_tensor, tf.constant(K.learning_phase())], [y_pred])\n",
    "    # if os.path.exists(join(path_base, \"best_weights_680x26.h5\")):\n",
    "\n",
    "    #     model.load_weights(join(path_base, \"best_weights_680x26.h5\"))\n",
    "    #     print('load weights from', join(path_base, \"best_weights_680x26.h5\"))\n",
    "\n",
    "    return model, test_func\n",
    "\n",
    "\n",
    "def get_batch(x, y, train=False, max_pred_len=4, input_length=8):\n",
    "\n",
    "    X = np.expand_dims(x, axis=3)\n",
    "    X = x  # for model2\n",
    "#     labels = np.ones((y.shape[0], max_pred_len)) *  -1 # 3 # , dtype=np.uint8\n",
    "    labels = y\n",
    "\n",
    "    input_length = np.ones([x.shape[0], 1]) * (input_length - 2)\n",
    "#     label_length = np.ones([y.shape[0], 1])\n",
    "    label_length = np.sum(labels > 0, axis=1)\n",
    "    label_length = np.expand_dims(label_length, 1)\n",
    "\n",
    "    inputs = {'the_input': X,\n",
    "              'the_labels': labels,\n",
    "              'input_length': input_length,\n",
    "              'label_length': label_length,\n",
    "              }\n",
    "    # dummy data for dummy loss function\n",
    "    outputs = {'ctc': np.zeros([x.shape[0]])}\n",
    "    return (inputs, outputs)\n",
    "\n",
    "\n",
    "def decode_batch(test_func, batch):\n",
    "    out = test_func([batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "#         outstr = labels_to_text(out_best)\n",
    "        ret.append(out_best)\n",
    "    return ret\n",
    "\n",
    "\n",
    "class MetricCallback(tensorflow.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, test_func, x, y, idx2w, num_test_words=18, info='this is test'):\n",
    "        self.test_func = test_func\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.idx2w = idx2w\n",
    "        self.num_test_words = num_test_words\n",
    "        self.info = info\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        y_pred = decode_batch(self.test_func, self.x[0:self.num_test_words])\n",
    "        y_true = self.y[:self.num_test_words]\n",
    "        y_pred = [''.join(map(lambda x: self.idx2w[x], pred))\n",
    "                  for pred in y_pred]\n",
    "        y_true = [''.join(map(lambda x: self.idx2w[x], true))\n",
    "                  for true in y_true]\n",
    "\n",
    "        random_idx = np.random.randint(0, self.num_test_words)\n",
    "\n",
    "        print('\\n'+self.info)\n",
    "        print('pred=', y_pred[random_idx])\n",
    "        print('true=', y_true[random_idx])\n",
    "\n",
    "        num_shot = sum([len(set(pred) & set(true))\n",
    "                       for pred, true in zip(y_true, y_pred)])\n",
    "        num_true = sum([len(true) for true in y_true])\n",
    "        print('accuracy:', num_shot / num_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 　选择使用的GPU\n",
    "path_base = './dataset/data_thchs30'\n",
    "path_data = join(path_base, 'data')\n",
    "K.set_learning_phase(1)  # set learning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from npy (13388, 680, 26)\n",
      "load from text file 13388\n",
      "load tok\n",
      "num of words, 2883\n",
      "max_len 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13388, 48)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1：创建mfcc特征矩阵，如果已经存在，则直接读取，否则重新创建\n",
    "if not os.path.exists(join(path_base, 'mfcc_vec_680x26'+'.npy')):\n",
    "    wav_files = glob.glob(join(path_data, '*.wav'))\n",
    "    wav_files.sort()\n",
    "    print('num of wav files', len(wav_files), 'ready to create mfcc mat')\n",
    "    create_mfcc_mat(wav_files[:], path=path_base)  # 第一次创建使用\n",
    "else:\n",
    "    mfcc_mat = get_mfcc_mat(path=path_base, save_name='mfcc_vec_680x26')\n",
    "    print('load from npy', mfcc_mat.shape)\n",
    "\n",
    "# step 2: 读取语音对应的文本，如果已经存在，则直接读取，否则重新创建\n",
    "text_path = join(path_base, 'all_texts.txt')\n",
    "if not os.path.exists(text_path):\n",
    "    text_files = glob.glob(join(path_data, '*.wav.trn'))\n",
    "    text_files.sort()\n",
    "    print('num of trn files', len(text_files), 'ready to create text file')\n",
    "    text_lines = get_text(text_files[:])\n",
    "    with codecs.open(text_path, mode='w', encoding='utf-8') as f_write:\n",
    "        for line in text_lines:\n",
    "            f_write.write(line + '\\n')\n",
    "else:\n",
    "    text_lines = [] \n",
    "    with codecs.open(text_path, encoding='utf-8') as f_read:\n",
    "        lines = f_read.readlines()\n",
    "        for line in lines:\n",
    "            text_lines.append(line.strip().replace(\" \", \"\"))\n",
    "    print('load from text file', len(text_lines))\n",
    "\n",
    "# step 3: 将文本转成与数字对应的映射关系，如果已经存在，则直接读取，否则重新创建\n",
    "# 不建议每次重新生成，避免字符与数字的对应关系前后不符\n",
    "pad_lines, tok = get_pad_seq(text_lines, maxlen=48)\n",
    "\n",
    "mfcc_mat.shape, pad_lines.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8146345a349ee509da9d4fd182b457ccbe591f61b447c7a0f2cf1b2fba90cca7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensorflow_gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
